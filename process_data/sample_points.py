import argparse
import trimesh
import numpy as np
import os
import traceback
from multiprocessing import Pool
from fnmatch import fnmatch
import multiprocessing as mp
from plyfile import PlyData, PlyElement

# def sample(arg):
#     path, name = arg
#     mesh = trimesh.load_mesh(os.path.join(path, name))
#
#     num_points = 100000
#     points = mesh.sample(num_points)
#
#     point_cloud = trimesh.points.PointCloud(points)
#
#     save_path = os.path.join(path, 'points3d.ply')
#     point_cloud.export(save_path)

def sample(arg):
    path, name = arg
    full_path = os.path.join(path, name)

    # path å½“å‰æŒ‡å‘çš„æ˜¯ models/ ç›®å½•
    # ä¾‹å¦‚: /root/autodl-tmp/ShapeNetCorePart/02773838/10a885f5971d9d4ce858db1dc3499392/models
    # target_dir ç¤ºä¾‹: /root/autodl-tmp/ShapeNetCorePart/02773838/10a885f5971d9d4ce858db1dc3499392
    target_dir = os.path.dirname(path)

    print(f"Processing: {full_path}")
    print(f"Saving to: {target_dir}")  # æ‰“å°ç›®æ ‡ç›®å½•ï¼Œæ–¹ä¾¿ç¡®è®¤

    try:
        loaded_data = trimesh.load(full_path)
        mesh = None

        if isinstance(loaded_data, trimesh.Trimesh):
            mesh = loaded_data

        elif isinstance(loaded_data, trimesh.Scene):
            merged_mesh = loaded_data.dump(concatenate=True)
            if merged_mesh is not None:
                mesh = merged_mesh
                print(f"[{name}] åœºæ™¯å·²åˆå¹¶ä¸ºå•ä¸€ç½‘æ ¼ã€‚")
            else:
                print(f"[{name}] åœºæ™¯ä¸­æ— æœ‰æ•ˆç½‘æ ¼å¯åˆå¹¶ï¼Œè·³è¿‡ã€‚")
                return
        else:
            print(f"[{name}] åŠ è½½ç»“æœç±»å‹ä¸º {type(loaded_data)}ï¼Œè·³è¿‡ã€‚")
            return

        if mesh is None:
            print(f"[{name}] æœªèƒ½è·å–æœ‰æ•ˆç½‘æ ¼å¯¹è±¡ï¼Œè·³è¿‡ã€‚")
            return

        num_points = 100000

        # ç¡®ä¿ç½‘æ ¼æœ‰é¢
        if mesh.faces.size == 0:
            print(f"[{name}] ç½‘æ ¼æ— é¢ï¼Œæ— æ³•é‡‡æ ·ï¼Œè·³è¿‡ã€‚")
            return

        # ä½¿ç”¨ Trimesh.sample() è·å–ä½ç½®å’Œé¢ç´¢å¼•
        # faces_idx æ˜¯æ¯ä¸ªç‚¹é‡‡æ ·è‡ªçš„é¢çš„ç´¢å¼•
        points, faces_idx = mesh.sample(num_points, return_index=True)

        # æ ¹æ®é¢ç´¢å¼•è·å–æ¯ä¸ªé‡‡æ ·ç‚¹çš„æ³•å‘é‡
        # mesh.face_normals[faces_idx] æä¾›äº†æ¯ä¸ªé‡‡æ ·ç‚¹æ‰€åœ¨é¢çš„æ³•å‘é‡
        normals = mesh.face_normals[faces_idx]

        # æ£€æŸ¥ normals æ•°ç»„çš„çŠ¶æ€
        print(f"[{name}] å‡†å¤‡å¯¼å‡º... æ£€æŸ¥æ³•å‘é‡æ•°ç»„:")
        print(f"   - Normals æ•°ç»„çš„å½¢çŠ¶: {normals.shape}")
        print(f"   - Normals æ•°ç»„çš„æ•°æ®ç±»å‹: {normals.dtype}")
        if np.isnan(normals).any():
            print(f"   - è­¦å‘Š: Normals æ•°ç»„ä¸­åŒ…å« NaN å€¼ï¼")
        if normals.shape[0] != num_points:
            print(f"   - é”™è¯¯: æ³•å‘é‡æ•°é‡ ({normals.shape[0]}) ä¸ç‚¹æ•° ({num_points}) ä¸åŒ¹é…ï¼")

        num_points = points.shape[0]
        vertex_data = np.empty(num_points, dtype=[
            ('x', 'f4'), ('y', 'f4'), ('z', 'f4'),
            ('nx', 'f4'), ('ny', 'f4'), ('nz', 'f4'),
            ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')  # é¢œè‰²é€šå¸¸æ˜¯ 8ä½æ— ç¬¦å·æ•´æ•° (0-255)
        ])

        # å¡«å……æ•°æ®
        vertex_data['x'] = points[:, 0].astype('f4')
        vertex_data['y'] = points[:, 1].astype('f4')
        vertex_data['z'] = points[:, 2].astype('f4')

        vertex_data['nx'] = normals[:, 0].astype('f4')
        vertex_data['ny'] = normals[:, 1].astype('f4')
        vertex_data['nz'] = normals[:, 2].astype('f4')

        # æ£€æŸ¥ mesh æ˜¯å¦æœ‰å¯ç”¨çš„é¢éƒ¨é¢œè‰²
        if hasattr(mesh.visual, 'face_colors') and len(mesh.visual.face_colors) > 0:
            # faces_idx æ˜¯æˆ‘ä»¬ä» mesh.sample å¾—åˆ°çš„æ¯ä¸ªç‚¹æ‰€åœ¨é¢çš„ç´¢å¼•
            # æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨å®ƒæ¥ç´¢å¼•é¢éƒ¨é¢œè‰²
            print("- ç½‘æ ¼å…·æœ‰é¢é¢œè‰²ï¼Œæ­£åœ¨æå–å¯¹åº”ç‚¹çš„é¢œè‰²ã€‚")
            point_colors = mesh.visual.face_colors[faces_idx]
        else:
            # å¦‚æœæ²¡æœ‰é¢œè‰²ï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„ç°è‰²
            print("- è­¦å‘Š: ç½‘æ ¼æ— é¢é¢œè‰²ï¼Œä½¿ç”¨é»˜è®¤é»‘è‰²ã€‚")
            point_colors = np.full((num_points, 4), [0, 0, 0, 255], dtype=np.uint8)

        # å¡«å……é¢œè‰²æ•°æ® (æ³¨æ„ trimesh é¢œè‰²å¯èƒ½æ˜¯ RGBAï¼Œæˆ‘ä»¬åªéœ€è¦ RGB)
        vertex_data['red'] = point_colors[:, 0]
        vertex_data['green'] = point_colors[:, 1]
        vertex_data['blue'] = point_colors[:, 2]

        # åˆ›å»º PlyElement
        vertex_element = PlyElement.describe(vertex_data, 'vertex')

        # æ„é€  PlyData å¹¶å†™å…¥æ–‡ä»¶
        save_path = os.path.join(target_dir, 'points3d.ply')
        PlyData([vertex_element], text=True).write(save_path)

        print(f"[{name}] âœ… æˆåŠŸé‡‡æ · {num_points} ç‚¹ (å«æ³•å‘é‡)ï¼Œå¹¶ä½¿ç”¨ plyfile æ‰‹åŠ¨ä¿å­˜åˆ° {save_path}ã€‚")
        print(f"   -> æ–‡ä»¶åº”åŒ…å«å­—æ®µ: {vertex_data.dtype.names}")

        # # æ„é€ åŒ…å«æ³•å‘é‡å’Œä½ç½®çš„ç‚¹äº‘
        # point_cloud = trimesh.points.PointCloud(
        #     vertices=points,
        #     vertex_normals=normals  # ç¡®ä¿è¿™é‡Œä¼ é€’çš„æ˜¯ vertex_normals
        # )
        #
        # save_path = os.path.join(target_dir, 'points3d.ply')
        # point_cloud.export(save_path)
        # print(f"[{name}] âœ… æˆåŠŸé‡‡æ · {num_points} ç‚¹ (å«æ³•å‘é‡) å¹¶ä¿å­˜åˆ° {save_path}ã€‚")

    except Exception as e:
        print(f"\nâŒ ERROR processing {full_path}: {e}")
        # traceback.print_exc()
        pass


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Sample points with normals and colors from 3D models in a directory.")
    parser.add_argument("-s", "--source", type=str, required=True,
                        help="Path to the root directory of the ShapeNet dataset (e.g., ShapeNetCorePart).")
    parser.add_argument("-w", "--workers", type=int, default=20,
                        help=f"Number of worker processes for parallel processing. Defaults to the number of CPU cores ({mp.cpu_count()}).")
    args = parser.parse_args()
    shapenet_folder = args.source
    num_workers = args.workers

    pattern = "*.obj"
    tasks = []
    for path, subdirs, files in os.walk(shapenet_folder):
        for name in files:
            if fnmatch(name, pattern):
                # path: .../models
                # name: model_normalized.obj
                tasks.append((path, name))

    print(f"{len(tasks)} objects left to be processed!")

    with Pool(num_workers) as pool:
        pool.map(sample, tasks)
    print("\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")